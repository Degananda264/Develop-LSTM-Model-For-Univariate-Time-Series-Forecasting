{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Univariant Time series Forecasting.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPGuz9BmQhAa+sEL45RkHCb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Degananda264/Develop-LSTM-Model-For-Univariate-Time-Series-Forecasting/blob/master/Univariant_Time_series_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuosjdEgJNWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# univariate lstm example\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iD2XpS4KXmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# preparing independent and dependent features\n",
        "def prepare_data(timeseries_data, n_features):\n",
        "\tX, y =[],[]\n",
        "\tfor i in range(len(timeseries_data)):\n",
        "\t\t# find the end of this pattern\n",
        "\t\tend_ix = i + n_features\n",
        "\t\t# check if we are beyond the sequence\n",
        "\t\tif end_ix > len(timeseries_data)-1:\n",
        "\t\t\tbreak\n",
        "\t\t# gather input and output parts of the pattern\n",
        "\t\tseq_x, seq_y = timeseries_data[i:end_ix], timeseries_data[end_ix]\n",
        "\t\tX.append(seq_x)\n",
        "\t\ty.append(seq_y)\n",
        "\treturn np.array(X), np.array(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oljhtoeQKgey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define input sequence\n",
        "timeseries_data = [110, 125, 133, 146, 158, 172, 187, 196, 210]\n",
        "# choose a number of time steps\n",
        "n_steps = 3\n",
        "# split into samples\n",
        "X, y = prepare_data(timeseries_data, n_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_1LoiWAKjnw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "2c60b702-4b7d-4842-f3a7-645978e2d1a7"
      },
      "source": [
        "print(X),print(y)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[110 125 133]\n",
            " [125 133 146]\n",
            " [133 146 158]\n",
            " [146 158 172]\n",
            " [158 172 187]\n",
            " [172 187 196]]\n",
            "[146 158 172 187 196 210]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zN0Lm4v7Km7v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "122aa1ce-ff7b-4e8b-fba8-e973220a9c21"
      },
      "source": [
        "\n",
        "X.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyXWbEqnKp8D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUGslRbsKtXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39f41e94-6b86-4a38-ee2f-4c43ba3944e6"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 3, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpvxVWBdKu8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9bad8c6a-8201-4b23-9a83-723356b48933"
      },
      "source": [
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
        "model.add(LSTM(50, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "# fit model\n",
        "model.fit(X, y, epochs=300)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 32135.4121\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 744us/step - loss: 31973.7559\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 31788.8613\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 31575.3750\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 781us/step - loss: 31328.1035\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 748us/step - loss: 31042.5137\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 724us/step - loss: 30712.5020\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 860us/step - loss: 30336.8594\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 727us/step - loss: 29920.8926\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 688us/step - loss: 29461.6250\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 704us/step - loss: 28966.6406\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 847us/step - loss: 28438.9395\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 736us/step - loss: 27877.3652\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 770us/step - loss: 27291.6562\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 715us/step - loss: 26657.1250\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 731us/step - loss: 25950.8047\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 771us/step - loss: 25144.2656\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 795us/step - loss: 24201.7559\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 746us/step - loss: 23104.7656\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 21895.0137\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 20647.7559\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 882us/step - loss: 19389.4375\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 18102.6660\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 777us/step - loss: 16767.1328\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 742us/step - loss: 15370.1953\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 818us/step - loss: 13967.5312\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 12585.9072\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 925us/step - loss: 11212.5273\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9821.2617\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8422.7266\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 856us/step - loss: 7034.4702\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 715us/step - loss: 5665.4453\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 946us/step - loss: 4296.0981\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 790us/step - loss: 2952.8281\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 706us/step - loss: 1713.5475\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 703us/step - loss: 720.8472\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 730us/step - loss: 128.2712\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 852us/step - loss: 52.2944\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 728us/step - loss: 481.0286\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 673us/step - loss: 1085.5874\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 836us/step - loss: 1521.6927\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 774us/step - loss: 1658.7349\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 807us/step - loss: 1530.9132\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 848us/step - loss: 1241.6187\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 733us/step - loss: 896.5674\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 695us/step - loss: 572.2274\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 740us/step - loss: 312.2365\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 829us/step - loss: 134.8787\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 733us/step - loss: 38.9335\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 888us/step - loss: 11.5705\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 771us/step - loss: 31.9914\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 971us/step - loss: 77.3449\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 757us/step - loss: 128.2414\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 755us/step - loss: 173.6182\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 950us/step - loss: 205.8557\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 771us/step - loss: 220.6520\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 977us/step - loss: 217.0782\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 761us/step - loss: 197.9668\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 169.4847\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 767us/step - loss: 137.3665\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 734us/step - loss: 105.1219\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 763us/step - loss: 74.7013\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 987us/step - loss: 48.0806\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 27.3660\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 790us/step - loss: 14.4889\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 743us/step - loss: 10.2664\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 726us/step - loss: 13.4500\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 759us/step - loss: 21.4325\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 715us/step - loss: 31.0118\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 883us/step - loss: 39.3960\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 890us/step - loss: 44.6868\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 746us/step - loss: 46.0822\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 737us/step - loss: 43.7639\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 731us/step - loss: 38.7079\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 924us/step - loss: 32.1963\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 25.3812\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 883us/step - loss: 19.2840\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 904us/step - loss: 14.5860\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 11.6385\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 747us/step - loss: 10.4351\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 774us/step - loss: 10.6908\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 731us/step - loss: 11.9512\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 747us/step - loss: 13.6997\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 731us/step - loss: 15.4547\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 775us/step - loss: 16.8387\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 836us/step - loss: 17.6147\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 17.6950\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 914us/step - loss: 17.1263\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 759us/step - loss: 16.0574\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 730us/step - loss: 14.6968\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 725us/step - loss: 13.2685\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 800us/step - loss: 11.9786\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 767us/step - loss: 10.9789\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 715us/step - loss: 10.3515\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 10.1044\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 704us/step - loss: 10.1813\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 711us/step - loss: 10.4799\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 731us/step - loss: 10.8781\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 777us/step - loss: 11.2577\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 925us/step - loss: 11.5241\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 748us/step - loss: 11.6253\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 744us/step - loss: 11.5481\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 755us/step - loss: 11.3109\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 803us/step - loss: 10.9580\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 957us/step - loss: 10.5392\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 10.0937\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.6670\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 874us/step - loss: 9.3138\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 732us/step - loss: 8.9637\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 736us/step - loss: 8.7219\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 765us/step - loss: 8.3995\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 767us/step - loss: 8.2702\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 759us/step - loss: 7.9345\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 741us/step - loss: 7.8170\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 787us/step - loss: 7.5693\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 834us/step - loss: 7.5292\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 767us/step - loss: 7.2099\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 727us/step - loss: 7.1156\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 741us/step - loss: 6.8501\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 727us/step - loss: 6.8169\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 738us/step - loss: 6.5311\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 700us/step - loss: 6.4549\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 709us/step - loss: 6.1858\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 710us/step - loss: 6.1183\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 823us/step - loss: 5.8604\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 819us/step - loss: 5.7353\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 745us/step - loss: 5.5388\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3810\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 748us/step - loss: 5.2572\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 768us/step - loss: 5.0463\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 716us/step - loss: 4.9786\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 758us/step - loss: 4.7567\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 705us/step - loss: 4.6431\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 896us/step - loss: 4.5114\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 836us/step - loss: 4.3424\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 781us/step - loss: 4.2613\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 764us/step - loss: 4.1062\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 953us/step - loss: 4.0184\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9270\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 793us/step - loss: 3.7997\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 706us/step - loss: 3.7722\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 725us/step - loss: 3.7639\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 738us/step - loss: 3.6293\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 791us/step - loss: 3.6183\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 920us/step - loss: 3.6417\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 996us/step - loss: 3.5152\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5148\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 760us/step - loss: 3.5736\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 735us/step - loss: 3.4660\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 770us/step - loss: 3.4758\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 751us/step - loss: 3.5370\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 837us/step - loss: 3.4479\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 745us/step - loss: 3.4679\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 745us/step - loss: 3.5178\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 736us/step - loss: 3.4379\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 753us/step - loss: 3.4696\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 772us/step - loss: 3.5008\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 815us/step - loss: 3.4251\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 900us/step - loss: 3.4694\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 755us/step - loss: 3.4759\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 737us/step - loss: 3.4072\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 807us/step - loss: 3.4613\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 819us/step - loss: 3.4387\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3871\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 772us/step - loss: 3.4402\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 744us/step - loss: 3.3926\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 706us/step - loss: 3.3684\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 741us/step - loss: 3.4034\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3485\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3500\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 956us/step - loss: 3.3599\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 759us/step - loss: 3.3176\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 746us/step - loss: 3.3310\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 923us/step - loss: 3.3263\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 784us/step - loss: 3.2996\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3122\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 730us/step - loss: 3.3020\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 730us/step - loss: 3.2859\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 771us/step - loss: 3.2942\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 740us/step - loss: 3.2832\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 735us/step - loss: 3.2722\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 734us/step - loss: 3.2763\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 784us/step - loss: 3.2664\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 752us/step - loss: 3.2566\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 712us/step - loss: 3.2575\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 733us/step - loss: 3.2493\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 793us/step - loss: 3.2389\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 972us/step - loss: 3.2378\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2307\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2195\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 740us/step - loss: 3.2115\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 762us/step - loss: 3.2090\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 706us/step - loss: 3.2068\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 693us/step - loss: 3.2034\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 806us/step - loss: 3.1938\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 900us/step - loss: 3.1802\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 746us/step - loss: 3.1699\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 740us/step - loss: 3.1652\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1633\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 949us/step - loss: 3.1607\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 735us/step - loss: 3.1541\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 836us/step - loss: 3.1451\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 811us/step - loss: 3.1346\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 731us/step - loss: 3.1269\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 738us/step - loss: 3.1184\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 755us/step - loss: 3.1122\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 836us/step - loss: 3.1070\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 814us/step - loss: 3.1030\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 931us/step - loss: 3.1022\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 731us/step - loss: 3.1082\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 762us/step - loss: 3.1303\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 750us/step - loss: 3.1592\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 784us/step - loss: 3.1958\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 800us/step - loss: 3.1430\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 750us/step - loss: 3.0784\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 805us/step - loss: 3.0530\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 731us/step - loss: 3.0842\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 749us/step - loss: 3.1200\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 947us/step - loss: 3.0863\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 719us/step - loss: 3.0388\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 717us/step - loss: 3.0251\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 767us/step - loss: 3.0488\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 787us/step - loss: 3.0684\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0399\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 817us/step - loss: 3.0057\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 820us/step - loss: 2.9939\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 796us/step - loss: 3.0066\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 876us/step - loss: 3.0267\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 836us/step - loss: 3.0245\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 782us/step - loss: 3.0117\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 845us/step - loss: 2.9811\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 728us/step - loss: 2.9606\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 729us/step - loss: 2.9554\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 733us/step - loss: 2.9625\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 740us/step - loss: 2.9793\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 810us/step - loss: 2.9956\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 742us/step - loss: 3.0262\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 722us/step - loss: 3.0202\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 729us/step - loss: 3.0072\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 741us/step - loss: 2.9491\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 729us/step - loss: 2.9156\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 764us/step - loss: 2.9208\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 713us/step - loss: 2.9441\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 825us/step - loss: 2.9601\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 778us/step - loss: 2.9335\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 732us/step - loss: 2.9019\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 763us/step - loss: 2.8866\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 723us/step - loss: 2.8957\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 740us/step - loss: 2.9048\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 789us/step - loss: 2.8978\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 768us/step - loss: 2.8828\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 928us/step - loss: 2.8665\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 780us/step - loss: 2.8595\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8612\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 709us/step - loss: 2.8649\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 902us/step - loss: 2.8680\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 855us/step - loss: 2.8639\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.8587\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 782us/step - loss: 2.8488\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 721us/step - loss: 2.8396\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 777us/step - loss: 2.8293\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 735us/step - loss: 2.8207\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 724us/step - loss: 2.8133\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 726us/step - loss: 2.8071\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 814us/step - loss: 2.8032\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 889us/step - loss: 2.8000\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 765us/step - loss: 2.7986\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 740us/step - loss: 2.8021\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 719us/step - loss: 2.8160\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 710us/step - loss: 2.8660\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 727us/step - loss: 2.9573\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 716us/step - loss: 3.1821\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 721us/step - loss: 3.0997\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9183\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 723us/step - loss: 2.7578\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 720us/step - loss: 2.9152\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 723us/step - loss: 3.0153\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 764us/step - loss: 2.7697\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 923us/step - loss: 2.8391\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 766us/step - loss: 2.9687\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 762us/step - loss: 2.7579\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 723us/step - loss: 2.8268\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9155\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 740us/step - loss: 2.7366\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 802us/step - loss: 2.8324\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 705us/step - loss: 2.8677\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 719us/step - loss: 2.7214\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 829us/step - loss: 2.8395\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 710us/step - loss: 2.8239\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 725us/step - loss: 2.7141\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 782us/step - loss: 2.8347\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7824\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 790us/step - loss: 2.7093\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 700us/step - loss: 2.8152\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7473\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 723us/step - loss: 2.6994\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 730us/step - loss: 2.7814\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 777us/step - loss: 2.7203\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 755us/step - loss: 2.6875\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 811us/step - loss: 2.7529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe52ff19048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkAxf_MGK00Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "84e17005-8192-495e-bb07-dea69e8cfbb0"
      },
      "source": [
        "# demonstrate prediction for next 10 days\n",
        "\n",
        "x_input =np.array([187, 196, 210])\n",
        "temp_input=list(x_input)\n",
        "lst_output=[]\n",
        "i=0\n",
        "while(i<10):\n",
        "    \n",
        "    if(len(temp_input)>3):\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        print(\"{} day input {}\".format(i,x_input))\n",
        "        #print(x_input)\n",
        "        x_input = x_input.reshape((1, n_steps, n_features))\n",
        "        #print(x_input)\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.append(yhat[0][0])\n",
        "        temp_input=temp_input[1:]\n",
        "        #print(temp_input)\n",
        "        lst_output.append(yhat[0][0])\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps, n_features))\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(yhat[0])\n",
        "        temp_input.append(yhat[0][0])\n",
        "        lst_output.append(yhat[0][0])\n",
        "        i=i+1\n",
        "    \n",
        "\n",
        "print(lst_output)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[223.32094]\n",
            "1 day input [196.         210.         223.32093811]\n",
            "1 day output [[233.65823]]\n",
            "2 day input [210.         223.32093811 233.65823364]\n",
            "2 day output [[246.45041]]\n",
            "3 day input [223.32094 233.65823 246.45041]\n",
            "3 day output [[258.05637]]\n",
            "4 day input [233.65823 246.45041 258.05637]\n",
            "4 day output [[268.64883]]\n",
            "5 day input [246.45041 258.05637 268.64883]\n",
            "5 day output [[280.08627]]\n",
            "6 day input [258.05637 268.64883 280.08627]\n",
            "6 day output [[290.69394]]\n",
            "7 day input [268.64883 280.08627 290.69394]\n",
            "7 day output [[300.96436]]\n",
            "8 day input [280.08627 290.69394 300.96436]\n",
            "8 day output [[311.36536]]\n",
            "9 day input [290.69394 300.96436 311.36536]\n",
            "9 day output [[321.28738]]\n",
            "[223.32094, 233.65823, 246.45041, 258.05637, 268.64883, 280.08627, 290.69394, 300.96436, 311.36536, 321.28738]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZ0XSW8iLCnY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "208559f6-24aa-423f-e453-75880c4cfb61"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "day_new=np.arange(1,10)\n",
        "day_pred=np.arange(10,20)\n",
        "\n",
        "plt.plot(day_new,timeseries_data)\n",
        "plt.plot(day_pred,lst_output)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe52d093668>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfaN-hVbMKrL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}